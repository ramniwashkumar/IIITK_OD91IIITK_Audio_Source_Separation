{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okT-o-lJrs3G"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display as dsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HAvuKCS-r-V9",
    "outputId": "50c2d150-a89f-4dd4-9860-c5611404fe7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJRAUfGnsC90",
    "outputId": "73b92712-f6fe-4fd0-bdca-458d0b6ef56a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Classic Education - NightOwl.stem.mp4',\n",
       " 'ANiMAL - Clinic A.stem.mp4',\n",
       " 'ANiMAL - Easy Tiger.stem.mp4',\n",
       " 'ANiMAL - Rockshow.stem.mp4',\n",
       " \"Actions - Devil's Words.stem.mp4\",\n",
       " 'Actions - One Minute Smile.stem.mp4',\n",
       " 'Actions - South Of The Water.stem.mp4',\n",
       " 'Aimee Norwich - Child.stem.mp4',\n",
       " 'Alexander Ross - Goodbye Bolero.stem.mp4',\n",
       " 'Alexander Ross - Velvet Curtain.stem.mp4',\n",
       " 'Angela Thomas Wade - Milk Cow Blues.stem.mp4',\n",
       " 'Atlantis Bound - It Was My Fault For Waiting.stem.mp4',\n",
       " 'Auctioneer - Our Future Faces.stem.mp4',\n",
       " 'AvaLuna - Waterduct.stem.mp4',\n",
       " 'BigTroubles - Phantom.stem.mp4',\n",
       " 'Bill Chudziak - Children Of No-one.stem.mp4',\n",
       " 'Black Bloc - If You Want Success.stem.mp4',\n",
       " 'Celestial Shore - Die For Us.stem.mp4',\n",
       " 'Chris Durban - Celebrate.stem.mp4',\n",
       " 'Clara Berry And Wooldog - Air Traffic.stem.mp4',\n",
       " 'Clara Berry And Wooldog - Stella.stem.mp4',\n",
       " 'Clara Berry And Wooldog - Waltz For My Victims.stem.mp4',\n",
       " 'Cnoc An Tursa - Bannockburn.stem.mp4',\n",
       " 'Creepoid - OldTree.stem.mp4',\n",
       " 'Dark Ride - Burning Bridges.stem.mp4',\n",
       " 'Dreamers Of The Ghetto - Heavy Love.stem.mp4',\n",
       " 'Drumtracks - Ghost Bitch.stem.mp4',\n",
       " 'Faces On Film - Waiting For Ga.stem.mp4',\n",
       " 'Fergessen - Back From The Start.stem.mp4',\n",
       " 'Fergessen - Nos Palpitants.stem.mp4',\n",
       " 'Fergessen - The Wind.stem.mp4',\n",
       " 'Flags - 54.stem.mp4',\n",
       " 'Giselle - Moss.stem.mp4',\n",
       " 'Grants - PunchDrunk.stem.mp4',\n",
       " 'Helado Negro - Mitad Del Mundo.stem.mp4',\n",
       " 'Hezekiah Jones - Borrowed Heart.stem.mp4',\n",
       " 'Hollow Ground - Left Blind.stem.mp4',\n",
       " 'Hop Along - Sister Cities.stem.mp4',\n",
       " 'Invisible Familiars - Disturbing Wildlife.stem.mp4',\n",
       " 'James May - All Souls Moon.stem.mp4',\n",
       " 'James May - Dont Let Go.stem.mp4',\n",
       " 'James May - If You Say.stem.mp4',\n",
       " 'James May - On The Line.stem.mp4',\n",
       " 'Jay Menon - Through My Eyes.stem.mp4',\n",
       " 'Johnny Lokke - Promises & Lies.stem.mp4',\n",
       " 'Johnny Lokke - Whisper To A Scream.stem.mp4',\n",
       " 'Jokers, Jacks & Kings - Sea Of Leaves.stem.mp4',\n",
       " 'Leaf - Come Around.stem.mp4',\n",
       " 'Leaf - Summerghost.stem.mp4',\n",
       " 'Leaf - Wicked.stem.mp4',\n",
       " 'Lushlife - Toynbee Suite.stem.mp4',\n",
       " 'Matthew Entwistle - Dont You Ever.stem.mp4',\n",
       " 'Meaxic - Take A Step.stem.mp4',\n",
       " 'Meaxic - You Listen.stem.mp4',\n",
       " 'Music Delta - 80s Rock.stem.mp4',\n",
       " 'Music Delta - Beatles.stem.mp4',\n",
       " 'Music Delta - Britpop.stem.mp4',\n",
       " 'Music Delta - Country1.stem.mp4',\n",
       " 'Music Delta - Country2.stem.mp4',\n",
       " 'Music Delta - Disco.stem.mp4',\n",
       " 'Music Delta - Gospel.stem.mp4',\n",
       " 'Music Delta - Grunge.stem.mp4',\n",
       " 'Music Delta - Hendrix.stem.mp4',\n",
       " 'Music Delta - Punk.stem.mp4',\n",
       " 'Music Delta - Reggae.stem.mp4',\n",
       " 'Music Delta - Rock.stem.mp4',\n",
       " 'Music Delta - Rockabilly.stem.mp4',\n",
       " 'Night Panther - Fire.stem.mp4',\n",
       " 'North To Alaska - All The Same.stem.mp4',\n",
       " 'Patrick Talbot - A Reason To Leave.stem.mp4',\n",
       " 'Patrick Talbot - Set Me Free.stem.mp4',\n",
       " \"Phre The Eon - Everybody's Falling Apart.stem.mp4\",\n",
       " 'Port St Willow - Stay Even.stem.mp4',\n",
       " 'Remember December - C U Next Time.stem.mp4',\n",
       " 'Secret Mountains - High Horse.stem.mp4',\n",
       " 'Skelpolu - Human Mistakes.stem.mp4',\n",
       " 'Skelpolu - Together Alone.stem.mp4',\n",
       " 'Snowmine - Curfews.stem.mp4',\n",
       " \"Spike Mullings - Mike's Sulking.stem.mp4\",\n",
       " 'St Vitus - Word Gets Around.stem.mp4',\n",
       " 'Steven Clark - Bounty.stem.mp4',\n",
       " 'Strand Of Oaks - Spacestation.stem.mp4',\n",
       " 'Sweet Lights - You Let Me Down.stem.mp4',\n",
       " 'Swinging Steaks - Lost My Way.stem.mp4',\n",
       " 'The Districts - Vermont.stem.mp4',\n",
       " 'The Long Wait - Back Home To Blue.stem.mp4',\n",
       " 'The Scarlet Brand - Les Fleurs Du Mal.stem.mp4',\n",
       " 'The So So Glos - Emergency.stem.mp4',\n",
       " \"The Wrong'Uns - Rothko.stem.mp4\",\n",
       " 'Tim Taler - Stalker.stem.mp4',\n",
       " 'Titanium - Haunted Age.stem.mp4',\n",
       " 'Traffic Experiment - Once More (With Feeling).stem.mp4',\n",
       " 'Traffic Experiment - Sirens.stem.mp4',\n",
       " 'Triviul - Angelsaint.stem.mp4',\n",
       " 'Triviul - Dorothy.stem.mp4',\n",
       " 'Voelund - Comfort Lives In Belief.stem.mp4',\n",
       " 'Wall Of Death - Femme.stem.mp4',\n",
       " 'Young Griffo - Blood To Bone.stem.mp4',\n",
       " 'Young Griffo - Facade.stem.mp4',\n",
       " 'Young Griffo - Pennies.stem.mp4']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=\"/content/gdrive/MyDrive/data/musdb18_train/\"\n",
    "import os\n",
    "dirs = os.listdir(files)\n",
    "# dirs = [\"A Classic Education - NightOwl.stem.mp4\",\"ANiMAL - Clinic A.stem.mp4\",\"ANiMAL - Easy Tiger.stem.mp4\"]\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KX5E5AaVEOYl"
   },
   "outputs": [],
   "source": [
    "mix_dirs = []\n",
    "bass_dirs = []\n",
    "for i in dirs:\n",
    "    mix_dirs.append(i+\"/mix.wav\")\n",
    "    bass_dirs.append(i+\"/bass.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYlfndogAt4o",
    "outputId": "fc48681e-d544-4b98-f39b-4a18d85ac3c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Classic Education - NightOwl.stem.mp4/mix.wav',\n",
       " 'ANiMAL - Clinic A.stem.mp4/mix.wav',\n",
       " 'ANiMAL - Easy Tiger.stem.mp4/mix.wav',\n",
       " 'ANiMAL - Rockshow.stem.mp4/mix.wav',\n",
       " \"Actions - Devil's Words.stem.mp4/mix.wav\",\n",
       " 'Actions - One Minute Smile.stem.mp4/mix.wav',\n",
       " 'Actions - South Of The Water.stem.mp4/mix.wav',\n",
       " 'Aimee Norwich - Child.stem.mp4/mix.wav',\n",
       " 'Alexander Ross - Goodbye Bolero.stem.mp4/mix.wav',\n",
       " 'Alexander Ross - Velvet Curtain.stem.mp4/mix.wav',\n",
       " 'Angela Thomas Wade - Milk Cow Blues.stem.mp4/mix.wav',\n",
       " 'Atlantis Bound - It Was My Fault For Waiting.stem.mp4/mix.wav',\n",
       " 'Auctioneer - Our Future Faces.stem.mp4/mix.wav',\n",
       " 'AvaLuna - Waterduct.stem.mp4/mix.wav',\n",
       " 'BigTroubles - Phantom.stem.mp4/mix.wav',\n",
       " 'Bill Chudziak - Children Of No-one.stem.mp4/mix.wav',\n",
       " 'Black Bloc - If You Want Success.stem.mp4/mix.wav',\n",
       " 'Celestial Shore - Die For Us.stem.mp4/mix.wav',\n",
       " 'Chris Durban - Celebrate.stem.mp4/mix.wav',\n",
       " 'Clara Berry And Wooldog - Air Traffic.stem.mp4/mix.wav',\n",
       " 'Clara Berry And Wooldog - Stella.stem.mp4/mix.wav',\n",
       " 'Clara Berry And Wooldog - Waltz For My Victims.stem.mp4/mix.wav',\n",
       " 'Cnoc An Tursa - Bannockburn.stem.mp4/mix.wav',\n",
       " 'Creepoid - OldTree.stem.mp4/mix.wav',\n",
       " 'Dark Ride - Burning Bridges.stem.mp4/mix.wav',\n",
       " 'Dreamers Of The Ghetto - Heavy Love.stem.mp4/mix.wav',\n",
       " 'Drumtracks - Ghost Bitch.stem.mp4/mix.wav',\n",
       " 'Faces On Film - Waiting For Ga.stem.mp4/mix.wav',\n",
       " 'Fergessen - Back From The Start.stem.mp4/mix.wav',\n",
       " 'Fergessen - Nos Palpitants.stem.mp4/mix.wav',\n",
       " 'Fergessen - The Wind.stem.mp4/mix.wav',\n",
       " 'Flags - 54.stem.mp4/mix.wav',\n",
       " 'Giselle - Moss.stem.mp4/mix.wav',\n",
       " 'Grants - PunchDrunk.stem.mp4/mix.wav',\n",
       " 'Helado Negro - Mitad Del Mundo.stem.mp4/mix.wav',\n",
       " 'Hezekiah Jones - Borrowed Heart.stem.mp4/mix.wav',\n",
       " 'Hollow Ground - Left Blind.stem.mp4/mix.wav',\n",
       " 'Hop Along - Sister Cities.stem.mp4/mix.wav',\n",
       " 'Invisible Familiars - Disturbing Wildlife.stem.mp4/mix.wav',\n",
       " 'James May - All Souls Moon.stem.mp4/mix.wav',\n",
       " 'James May - Dont Let Go.stem.mp4/mix.wav',\n",
       " 'James May - If You Say.stem.mp4/mix.wav',\n",
       " 'James May - On The Line.stem.mp4/mix.wav',\n",
       " 'Jay Menon - Through My Eyes.stem.mp4/mix.wav',\n",
       " 'Johnny Lokke - Promises & Lies.stem.mp4/mix.wav',\n",
       " 'Johnny Lokke - Whisper To A Scream.stem.mp4/mix.wav',\n",
       " 'Jokers, Jacks & Kings - Sea Of Leaves.stem.mp4/mix.wav',\n",
       " 'Leaf - Come Around.stem.mp4/mix.wav',\n",
       " 'Leaf - Summerghost.stem.mp4/mix.wav',\n",
       " 'Leaf - Wicked.stem.mp4/mix.wav',\n",
       " 'Lushlife - Toynbee Suite.stem.mp4/mix.wav',\n",
       " 'Matthew Entwistle - Dont You Ever.stem.mp4/mix.wav',\n",
       " 'Meaxic - Take A Step.stem.mp4/mix.wav',\n",
       " 'Meaxic - You Listen.stem.mp4/mix.wav',\n",
       " 'Music Delta - 80s Rock.stem.mp4/mix.wav',\n",
       " 'Music Delta - Beatles.stem.mp4/mix.wav',\n",
       " 'Music Delta - Britpop.stem.mp4/mix.wav',\n",
       " 'Music Delta - Country1.stem.mp4/mix.wav',\n",
       " 'Music Delta - Country2.stem.mp4/mix.wav',\n",
       " 'Music Delta - Disco.stem.mp4/mix.wav',\n",
       " 'Music Delta - Gospel.stem.mp4/mix.wav',\n",
       " 'Music Delta - Grunge.stem.mp4/mix.wav',\n",
       " 'Music Delta - Hendrix.stem.mp4/mix.wav',\n",
       " 'Music Delta - Punk.stem.mp4/mix.wav',\n",
       " 'Music Delta - Reggae.stem.mp4/mix.wav',\n",
       " 'Music Delta - Rock.stem.mp4/mix.wav',\n",
       " 'Music Delta - Rockabilly.stem.mp4/mix.wav',\n",
       " 'Night Panther - Fire.stem.mp4/mix.wav',\n",
       " 'North To Alaska - All The Same.stem.mp4/mix.wav',\n",
       " 'Patrick Talbot - A Reason To Leave.stem.mp4/mix.wav',\n",
       " 'Patrick Talbot - Set Me Free.stem.mp4/mix.wav',\n",
       " \"Phre The Eon - Everybody's Falling Apart.stem.mp4/mix.wav\",\n",
       " 'Port St Willow - Stay Even.stem.mp4/mix.wav',\n",
       " 'Remember December - C U Next Time.stem.mp4/mix.wav',\n",
       " 'Secret Mountains - High Horse.stem.mp4/mix.wav',\n",
       " 'Skelpolu - Human Mistakes.stem.mp4/mix.wav',\n",
       " 'Skelpolu - Together Alone.stem.mp4/mix.wav',\n",
       " 'Snowmine - Curfews.stem.mp4/mix.wav',\n",
       " \"Spike Mullings - Mike's Sulking.stem.mp4/mix.wav\",\n",
       " 'St Vitus - Word Gets Around.stem.mp4/mix.wav',\n",
       " 'Steven Clark - Bounty.stem.mp4/mix.wav',\n",
       " 'Strand Of Oaks - Spacestation.stem.mp4/mix.wav',\n",
       " 'Sweet Lights - You Let Me Down.stem.mp4/mix.wav',\n",
       " 'Swinging Steaks - Lost My Way.stem.mp4/mix.wav',\n",
       " 'The Districts - Vermont.stem.mp4/mix.wav',\n",
       " 'The Long Wait - Back Home To Blue.stem.mp4/mix.wav',\n",
       " 'The Scarlet Brand - Les Fleurs Du Mal.stem.mp4/mix.wav',\n",
       " 'The So So Glos - Emergency.stem.mp4/mix.wav',\n",
       " \"The Wrong'Uns - Rothko.stem.mp4/mix.wav\",\n",
       " 'Tim Taler - Stalker.stem.mp4/mix.wav',\n",
       " 'Titanium - Haunted Age.stem.mp4/mix.wav',\n",
       " 'Traffic Experiment - Once More (With Feeling).stem.mp4/mix.wav',\n",
       " 'Traffic Experiment - Sirens.stem.mp4/mix.wav',\n",
       " 'Triviul - Angelsaint.stem.mp4/mix.wav',\n",
       " 'Triviul - Dorothy.stem.mp4/mix.wav',\n",
       " 'Voelund - Comfort Lives In Belief.stem.mp4/mix.wav',\n",
       " 'Wall Of Death - Femme.stem.mp4/mix.wav',\n",
       " 'Young Griffo - Blood To Bone.stem.mp4/mix.wav',\n",
       " 'Young Griffo - Facade.stem.mp4/mix.wav',\n",
       " 'Young Griffo - Pennies.stem.mp4/mix.wav']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "67zmFYBo9Dp4"
   },
   "outputs": [],
   "source": [
    "sample_rate = 8000\n",
    "n_fft = 255\n",
    "hop_length_fft = 63\n",
    "nb_samples = 50\n",
    "batch_size = 20\n",
    "epochs = 10\n",
    "frame_length = 8064\n",
    "hop_length_frame = 8064\n",
    "min_duration = 1\n",
    "categories = [\"mix.wav\",\"bass.wav\"]\n",
    "dim_square_spec = int(n_fft / 2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_ai3YDIshHu"
   },
   "outputs": [],
   "source": [
    "def audio_to_audio_frame_stack(sound_data, frame_length, hop_length_frame):\n",
    "    \"\"\"This function take an audio and split into several frame\n",
    "       in a numpy matrix of size (nb_frame,frame_length)\"\"\"\n",
    "\n",
    "    sequence_sample_length = sound_data.shape[0]\n",
    "\n",
    "    sound_data_list = [sound_data[start:start + frame_length] for start in range(\n",
    "    0, sequence_sample_length - frame_length + 1, hop_length_frame)]  # get sliding windows\n",
    "    sound_data_array = np.vstack(sound_data_list)\n",
    "\n",
    "    return sound_data_array\n",
    "\n",
    "\n",
    "def audio_files_to_numpy(audio_dir, list_audio_files, sample_rate, frame_length, hop_length_frame, min_duration):\n",
    "    \"\"\"This function take audio files of a directory and merge them\n",
    "    in a numpy matrix of size (nb_frame,frame_length) for a sliding window of size hop_length_frame\"\"\"\n",
    "\n",
    "    list_sound_array = []\n",
    "\n",
    "    for file in list_audio_files:\n",
    "        # open the audio file\n",
    "        y, sr = librosa.load(os.path.join(audio_dir,file), sr=sample_rate)\n",
    "        total_duration = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        if (total_duration >= min_duration):\n",
    "            list_sound_array.append(audio_to_audio_frame_stack(\n",
    "                y, frame_length, hop_length_frame))\n",
    "        else:\n",
    "            print(\n",
    "                f\"The following file {os.path.join(audio_dir,file)} is below the min duration\")\n",
    "\n",
    "    return np.vstack(list_sound_array)\n",
    "\n",
    "def audio_to_magnitude_db_and_phase(n_fft, hop_length_fft, audio):\n",
    "    \"\"\"This function takes an audio and convert into spectrogram,\n",
    "       it returns the magnitude in dB and the phase\"\"\"\n",
    "\n",
    "    stftaudio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length_fft)\n",
    "    stftaudio_magnitude, stftaudio_phase = librosa.magphase(stftaudio)\n",
    "\n",
    "    stftaudio_magnitude_db = librosa.amplitude_to_db(\n",
    "        stftaudio_magnitude, ref=np.max)\n",
    "\n",
    "    return stftaudio_magnitude_db, stftaudio_phase\n",
    "\n",
    "def numpy_audio_to_matrix_spectrogram(numpy_audio, dim_square_spec, n_fft, hop_length_fft):\n",
    "    \"\"\"This function takes as input a numpy audi of size (nb_frame,frame_length), and return\n",
    "    a numpy containing the matrix spectrogram for amplitude in dB and phase. It will have the size\n",
    "    (nb_frame,dim_square_spec,dim_square_spec)\"\"\"\n",
    "\n",
    "    nb_audio = numpy_audio.shape[0]\n",
    "\n",
    "    m_mag_db = np.zeros((nb_audio, dim_square_spec, dim_square_spec))\n",
    "    m_phase = np.zeros((nb_audio, dim_square_spec, dim_square_spec), dtype=complex)\n",
    "\n",
    "    for i in range(nb_audio):\n",
    "        m_mag_db[i, :, :], m_phase[i, :, :] = audio_to_magnitude_db_and_phase(\n",
    "            n_fft, hop_length_fft, numpy_audio[i])\n",
    "\n",
    "    return m_mag_db, m_phase\n",
    "\n",
    "def magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, stftaudio_magnitude_db, stftaudio_phase):\n",
    "    \"\"\"This functions reverts a spectrogram to an audio\"\"\"\n",
    "\n",
    "    stftaudio_magnitude_rev = librosa.db_to_amplitude(stftaudio_magnitude_db, ref=1.0)\n",
    "\n",
    "    # taking magnitude and phase of audio\n",
    "    audio_reverse_stft = stftaudio_magnitude_rev * stftaudio_phase\n",
    "    audio_reconstruct = librosa.core.istft(audio_reverse_stft, hop_length=hop_length_fft, length=frame_length)\n",
    "\n",
    "    return audio_reconstruct\n",
    "\n",
    "def matrix_spectrogram_to_numpy_audio(m_mag_db, m_phase, frame_length, hop_length_fft)  :\n",
    "    \"\"\"This functions reverts the matrix spectrograms to numpy audio\"\"\"\n",
    "\n",
    "    list_audio = []\n",
    "\n",
    "    nb_spec = m_mag_db.shape[0]\n",
    "\n",
    "    for i in range(nb_spec):\n",
    "\n",
    "        audio_reconstruct = magnitude_db_and_phase_to_audio(frame_length, hop_length_fft, m_mag_db[i], m_phase[i])\n",
    "        list_audio.append(audio_reconstruct)\n",
    "\n",
    "    return np.vstack(list_audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-oYaDxbMvPty"
   },
   "outputs": [],
   "source": [
    "mix = audio_files_to_numpy(files,mix_dirs,sample_rate,frame_length,hop_length_frame,min_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QsQoXz4JVe_3",
    "outputId": "29537706-d340-40a5-eec2-5fb49a50ae47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22641, 8064)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1m3HuClzHeI7"
   },
   "outputs": [],
   "source": [
    "bass = audio_files_to_numpy(files,bass_dirs,sample_rate,frame_length,hop_length_frame,min_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLZ7apY9VpN0"
   },
   "outputs": [],
   "source": [
    "bass.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Myp-RMv_CZoY"
   },
   "outputs": [],
   "source": [
    "dim_square_spec = int(n_fft / 2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rs9tMuWJZ_Kn",
    "outputId": "a72af9b8-2692-4ff9-eff9-00264e9b0112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607, 128, 128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Amplitude and phase of the sounds\n",
    "m_amp_db_voice,  m_pha_voice = numpy_audio_to_matrix_spectrogram(\n",
    "        bass, dim_square_spec, n_fft, hop_length_fft)\n",
    "# m_amp_db_noise,  m_pha_noise = numpy_audio_to_matrix_spectrogram(\n",
    "#         prod_noise, dim_square_spec, n_fft, hop_length_fft)\n",
    "# m_amp_db_noisy_voice,  m_pha_noisy_voice = numpy_audio_to_matrix_spectrogram(\n",
    "        # mix, dim_square_spec, n_fft, hop_length_fft)\n",
    "\n",
    "# path = \"/content/gdrive/MyDrive/numpy/\"\n",
    "\n",
    "# # Save to disk for Training / QC\n",
    "# np.save(path + 'vocals50', vocals)\n",
    "# # np.save(path_save_time_serie + 'noise_timeserie', prod_noise)\n",
    "# # np.save(path + 'mix50', mix)\n",
    "\n",
    "\n",
    "# np.save(path + 'vocals50_amp_db', m_amp_db_voice)\n",
    "# # np.save(path_save_spectrogram + 'noise_amp_db', m_amp_db_noise)\n",
    "# # np.save(path + 'mix50_amp_db', m_amp_db_noisy_voice)\n",
    "\n",
    "# np.save(path + 'vocals50_pha_db', m_pha_voice)\n",
    "# # np.save(path_save_spectrogram + 'noise_pha_db', m_pha_noise)\n",
    "# # np.save(path + 'mix50_pha_db', m_pha_noisy_voice)\n",
    "\n",
    "m_amp_db_voice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KO2DxwVIUUDu",
    "outputId": "2b2b2dcf-b476-49b3-d846-c958066397fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(907, 256, 256)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_amp_db_noisy_voice,  m_pha_noisy_voice = numpy_audio_to_matrix_spectrogram(\n",
    "        mix, dim_square_spec, n_fft, hop_length_fft)\n",
    "\n",
    "# path = \"/content/gdrive/MyDrive/numpy/\"\n",
    "# np.save(path + 'mix50', mix)\n",
    "# np.save(path + 'mix50_amp_db', m_amp_db_noisy_voice)\n",
    "# np.save(path + 'mix50_pha_db', m_pha_noisy_voice)\n",
    "\n",
    "m_amp_db_noisy_voice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmL0VyPoo4vo"
   },
   "outputs": [],
   "source": [
    "path = \"/content/gdrive/MyDrive/numpy/\"\n",
    "\n",
    "# Save to disk for Training / QC\n",
    "np.save(path + 'bass100', bass)\n",
    "# np.save(path_save_time_serie + 'noise_timeserie', prod_noise)\n",
    "np.save(path + 'mix100', mix)\n",
    "\n",
    "\n",
    "np.save(path + 'bass100_amp_db', m_amp_db_voice)\n",
    "# np.save(path_save_spectrogram + 'noise_amp_db', m_amp_db_noise)\n",
    "np.save(path + 'mix100_amp_db', m_amp_db_noisy_voice)\n",
    "\n",
    "np.save(path + 'bass100_pha_db', m_pha_voice)\n",
    "# np.save(path_save_spectrogram + 'noise_pha_db', m_pha_noise)\n",
    "np.save(path + 'mix100_pha_db', m_pha_noisy_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bGiF5OUSdA9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, MaxPooling2D, Dropout, concatenate, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "#Unet network\n",
    "def unet(pretrained_weights = None,input_size = (128,128,1)):\n",
    "    #size filter input\n",
    "    size_filter_in = 32\n",
    "    #normal initialization of weights\n",
    "    kernel_init = 'he_normal'\n",
    "    #To apply leaky relu after the conv layer \n",
    "    activation_layer = None\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(inputs)\n",
    "    conv1 = LeakyReLU()(conv1)\n",
    "    conv1 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv1)\n",
    "    conv1 = LeakyReLU()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool1)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    conv2 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv2)\n",
    "    conv2 = LeakyReLU()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool2)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "    conv3 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv3)\n",
    "    conv3 = LeakyReLU()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool3)\n",
    "    conv4 = LeakyReLU()(conv4)\n",
    "    conv4 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv4)\n",
    "    conv4 = LeakyReLU()(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(size_filter_in*16, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(pool4)\n",
    "    conv5 = LeakyReLU()(conv5)\n",
    "    conv5 = Conv2D(size_filter_in*16, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv5)\n",
    "    conv5 = LeakyReLU()(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(size_filter_in*8, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(drop5))\n",
    "    up6 = LeakyReLU()(up6)\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge6)\n",
    "    conv6 = LeakyReLU()(conv6)\n",
    "    conv6 = Conv2D(size_filter_in*8, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv6)\n",
    "    conv6 = LeakyReLU()(conv6)\n",
    "    up7 = Conv2D(size_filter_in*4, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(conv6))\n",
    "    up7 = LeakyReLU()(up7)\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge7)\n",
    "    conv7 = LeakyReLU()(conv7)\n",
    "    conv7 = Conv2D(size_filter_in*4, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv7)\n",
    "    conv7 = LeakyReLU()(conv7)\n",
    "    up8 = Conv2D(size_filter_in*2, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(conv7))\n",
    "    up8 = LeakyReLU()(up8)\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge8)\n",
    "    conv8 = LeakyReLU()(conv8)\n",
    "    conv8 = Conv2D(size_filter_in*2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv8)\n",
    "    conv8 = LeakyReLU()(conv8)\n",
    "\n",
    "    up9 = Conv2D(size_filter_in, 2, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(UpSampling2D(size = (2,2))(conv8))\n",
    "    up9 = LeakyReLU()(up9)\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(merge9)\n",
    "    conv9 = LeakyReLU()(conv9)\n",
    "    conv9 = Conv2D(size_filter_in, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv9)\n",
    "    conv9 = LeakyReLU()(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = activation_layer, padding = 'same', kernel_initializer = kernel_init)(conv9)\n",
    "    conv9 = LeakyReLU()(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'tanh')(conv9)\n",
    "\n",
    "    model = Model(inputs,conv10)\n",
    "\n",
    "    model.compile(optimizer = 'adam', loss = tf.keras.losses.Huber(), metrics = ['mae'])\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TY5bUg1TSi-P"
   },
   "outputs": [],
   "source": [
    "mix_mag = np.load(\"/content/gdrive/MyDrive/numpy/mix100_amp_db.npy\")\n",
    "bass_mag = np.load(\"/content/gdrive/MyDrive/numpy/bass100_amp_db.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viZmZA0YS1PB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i56czctIS4UO"
   },
   "outputs": [],
   "source": [
    "print(stats.describe(mix_mag.reshape(-1,1)))\n",
    "print(stats.describe(bass_mag.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxf0i79nS8gl"
   },
   "outputs": [],
   "source": [
    "mix_mag = (mix_mag - mix_mag.mean())/mix_mag.std()\n",
    "bass_mag = (bass_mag - bass_mag.mean())/bass_mag.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7GxGlZyWS-wL"
   },
   "outputs": [],
   "source": [
    "print(stats.describe(mix_mag.reshape(-1,1)))\n",
    "print(stats.describe(bass_mag.reshape(-1,1)))\n",
    "\n",
    "print(mix_mag.shape)\n",
    "print(bass_mag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XjMewq_TLSG"
   },
   "outputs": [],
   "source": [
    "X_in = mix_mag\n",
    "X_ou = bass_mag\n",
    "\n",
    "# X_ou = X_in - X_ou\n",
    "print(X_in.shape)\n",
    "print(X_ou.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZxL4BVjTTQu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#Reshape for training\n",
    "X_in = X_in[:,:,:]\n",
    "X_in = X_in.reshape(X_in.shape[0],X_in.shape[1],X_in.shape[2],1)\n",
    "X_ou = X_ou[:,:,:]\n",
    "X_ou = X_ou.reshape(X_ou.shape[0],X_ou.shape[1],X_ou.shape[2],1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_in, X_ou, test_size=0.20)\n",
    "\n",
    "#If training from pre-trained weights\n",
    "# generator_nn=unet(pretrained_weights = root_path+'mod_unet_last_weights.h5')\n",
    "\n",
    "#If training from scratch\n",
    "generator_nn=unet()\n",
    "#Save best models to disk\n",
    "checkpoint = ModelCheckpoint('/content/gdrive/My Drive/app/test/model-{epoch:03d}-{loss:03f}-{val_loss:03f}.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
    "\n",
    "generator_nn.summary()\n",
    "#Training\n",
    "history = generator_nn.fit(X_train, y_train, epochs=25, batch_size=32, shuffle=True, callbacks=[checkpoint], verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3wtsMdxTWdF"
   },
   "outputs": [],
   "source": [
    "#Plot training and validation loss\n",
    "from matplotlib import pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.yscale('log')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRy15iMkUCGe"
   },
   "outputs": [],
   "source": [
    "sample_rate = 8000\n",
    "n_fft = 255\n",
    "hop_length_fft = 63\n",
    "nb_samples = 50\n",
    "batch_size = 20\n",
    "epochs = 10\n",
    "frame_length = 8064\n",
    "hop_length_frame = 8064\n",
    "min_duration = 1\n",
    "categories = [\"mix.wav\",\"vocals.wav\"]\n",
    "dim_square_spec = int(n_fft / 2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stqYo6DHUEXi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ls = os.listdir(\"/content/gdrive/MyDrive/data/musdb18_test\")\n",
    "\n",
    "weights_path = \"/content/gdrive/MyDrive/app/\"\n",
    "name_model = \"model-018-0.000564-0.000618.h5\"\n",
    "\n",
    "audio_dir_prediction = \"/content/gdrive/MyDrive/data/musdb18_test\"\n",
    "dir_save_prediction = \"/content/gdrive/MyDrive/app/predictions_audio/\"\n",
    "l = []\n",
    "for i in ls:\n",
    "    l.append(i+\"/mix.wav\")\n",
    "audio_input_prediction = l[2:3]\n",
    "audio_output_prediction = \"bass.wav\"\n",
    "\n",
    "\n",
    "def scaled_in(matrix_spec):\n",
    "    \"global scaling apply to noisy voice spectrograms (scale between -1 and 1)\"\n",
    "    # matrix_spec = (matrix_spec + 46)/50\n",
    "    matrix_spec = (matrix_spec - (-39.59250678))/246.04414739\n",
    "    return matrix_spec\n",
    "\n",
    "# def scaled_ou(matrix_spec):\n",
    "#     \"global scaling apply to noise models spectrograms (scale between -1 and 1)\"\n",
    "#     # matrix_spec = (matrix_spec -6 )/82\n",
    "#     matrix_spec = (matrix_spec - (-39.2319582))/235.33391848\n",
    "#     return matrix_spec\n",
    "\n",
    "def inv_scaled_ou(matrix_spec):\n",
    "    \"inverse global scaling apply to noise models spectrograms\"\n",
    "    # matrix_spec = matrix_spec * 82 + 6\n",
    "    matrix_spec = matrix_spec * 511.57269939 + (-35.18166773)\n",
    "    return matrix_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNzyceDbUUC-"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "def prediction(weights_path, name_model, audio_dir_prediction, dir_save_prediction, audio_input_prediction,\n",
    "audio_output_prediction, sample_rate, min_duration, frame_length, hop_length_frame, n_fft, hop_length_fft):\n",
    "    \"\"\" This function takes as input pretrained weights, noisy voice sound to denoise, predict\n",
    "    the denoise sound and save it to disk.\n",
    "    \"\"\"\n",
    "\n",
    "    # # load json and create model\n",
    "    # json_file = open(weights_path+'/'+name_model+'.json', 'r')\n",
    "    # loaded_model_json = json_file.read()\n",
    "    # json_file.close()\n",
    "    # loaded_model = model_from_json(loaded_model_json)\n",
    "    # # load weights into new model\n",
    "    # loaded_model.load_weights(weights_path+'/'+name_model+'.h5')\n",
    "    from tensorflow import keras\n",
    "    loaded_model = keras.models.load_model(\"/content/gdrive/MyDrive/app/model-020-0.000841-0.000868.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "\n",
    "    # Extracting noise and voice from folder and convert to numpy\n",
    "    audio = audio_files_to_numpy(audio_dir_prediction, audio_input_prediction, sample_rate,\n",
    "                                 frame_length, hop_length_frame, min_duration)\n",
    "\n",
    "    #Dimensions of squared spectrogram\n",
    "    dim_square_spec = int(n_fft / 2) + 1\n",
    "    print(dim_square_spec)\n",
    "\n",
    "    # Create Amplitude and phase of the sounds\n",
    "    m_amp_db_audio,  m_pha_audio = numpy_audio_to_matrix_spectrogram(\n",
    "        audio, dim_square_spec, n_fft, hop_length_fft)\n",
    "\n",
    "    #global scaling to have distribution -1/1\n",
    "    X_in = scaled_in(m_amp_db_audio)\n",
    "    #Reshape for prediction\n",
    "    X_in = X_in.reshape(X_in.shape[0],X_in.shape[1],X_in.shape[2],1)\n",
    "    #Prediction using loaded network\n",
    "    X_pred = loaded_model.predict(X_in)\n",
    "    #Rescale back the noise model\n",
    "    inv_sca_X_pred = inv_scaled_ou(X_pred)\n",
    "    #Remove noise model from noisy speech\n",
    "    # X_denoise = m_amp_db_audio - inv_sca_X_pred[:,:,:,0]\n",
    "    # X_denoise = m_amp_db_audio - X_denoise\n",
    "    \n",
    "    X_denoise = inv_sca_X_pred[:,:,:,0]\n",
    "    #Reconstruct audio from denoised spectrogram and phase\n",
    "    print(X_denoise.shape)\n",
    "    print(m_pha_audio.shape)\n",
    "    print(frame_length)\n",
    "    print(hop_length_fft)\n",
    "    audio_denoise_recons = matrix_spectrogram_to_numpy_audio(X_denoise, m_pha_audio, frame_length, hop_length_fft)\n",
    "    #Number of frames\n",
    "    nb_samples = audio_denoise_recons.shape[0]\n",
    "    #Save all frames in one file\n",
    "    denoise_long = audio_denoise_recons.reshape(1, nb_samples * frame_length)*10\n",
    "    # librosa.output.write_wav(dir_save_prediction + audio_output_prediction, denoise_long[0, :], sample_rate)\n",
    "    fin = dir_save_prediction + audio_output_prediction\n",
    "    sf.write(\"test1.wav\", denoise_long[0, :], sample_rate, 'PCM_24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gflmiEPuUXvO"
   },
   "outputs": [],
   "source": [
    "prediction(weights_path, name_model, audio_dir_prediction, dir_save_prediction, audio_input_prediction, audio_output_prediction, sample_rate, min_duration, frame_length, hop_length_frame, n_fft, hop_length_fft)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bass.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
